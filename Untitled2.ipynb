{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "from imutils import paths\n",
    "#import pickl\n",
    "import os, sys\n",
    "import cv2\n",
    "from sklearn.metrics import accuracy_score\n",
    "from skimage.feature import local_binary_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63325\n",
      "63325\n"
     ]
    }
   ],
   "source": [
    "fp = open('train.txt',\"r\")\n",
    "image_paths=[]\n",
    "image_classes=[]\n",
    "for line in fp.readlines():\n",
    "    linee = line.strip().split(\" \") \n",
    "    image_paths.append(linee[0])\n",
    "    image_classes.append(linee[1])\n",
    "print(len(image_paths))\n",
    "print(len(image_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450\n",
      "450\n"
     ]
    }
   ],
   "source": [
    "fp = open('test.txt',\"r\")\n",
    "test_image_paths=[]\n",
    "test_image_classes=[]\n",
    "for line in fp.readlines():\n",
    "    linee = line.strip().split(\" \") \n",
    "    test_image_paths.append(linee[0])\n",
    "    test_image_classes.append(linee[1])\n",
    "print(len(test_image_paths))\n",
    "print(len(test_image_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450\n",
      "450\n"
     ]
    }
   ],
   "source": [
    "fp = open('val.txt',\"r\")\n",
    "val_image_paths=[]\n",
    "val_image_classes=[]\n",
    "for line in fp.readlines():\n",
    "    linee = line.strip().split(\" \") \n",
    "    val_image_paths.append(linee[0])\n",
    "    val_image_classes.append(linee[1])\n",
    "print(len(val_image_paths))\n",
    "print(len(val_image_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opimage(image_paths,image_classes):\n",
    "    imgs = []\n",
    "    time=1\n",
    "    allt=len(image_paths)\n",
    "    print(\"Calculating all the descriptors and keypoints...\")\n",
    "    for image_path in image_paths:\n",
    "        img  = cv.imread(image_path)\n",
    "        img = cv.cvtColor(img,cv.COLOR_BGR2GRAY) # Converts from one color space to another (grayscale)\n",
    "        img =cv2.resize(img,(64,64),interpolation=cv2.INTER_CUBIC)\n",
    "        #kp, des = sift.detectAndCompute(img,None)\n",
    "        imgs.append((img))\n",
    "        print(str(time)+\"/\"+str(allt), end=\"\\r\")\n",
    "        time=time+1\n",
    "    print(\"\\nDone!\")\n",
    "    return(imgs,image_paths,image_classes)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbp1(imgs,image_paths,image_classes):\n",
    "    radius = 1  # LBP算法中範圍半徑的取值\n",
    "    n_points = 8 * radius # 領域像素點數\n",
    "    des_list = []\n",
    "    time=1\n",
    "    allt=len(imgs)\n",
    "    for im in imgs:\n",
    "        lbp = local_binary_pattern(im, n_points, radius)\n",
    "        max_bins = int(lbp.max() + 1)\n",
    "        des,_ = np.histogram(lbp,bins=max_bins, range=(0, max_bins))\n",
    "        if str(des) != 'None':\n",
    "            des_list.append((des))\n",
    "            print(str(time)+\"/\"+str(allt), end=\"\\r\")\n",
    "            time=time+1\n",
    "        else:\n",
    "            print(image_paths[time-1])\n",
    "            del image_classes[time-1]\n",
    "            del image_paths[time-1]\n",
    "    print(\"\\nDone!\")\n",
    "   # return(scaled_im_features,image_paths,image_classes,stdSlr,k,voc)\n",
    "    return(des_list,image_paths,image_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "def mlpf(scaled_im_features,image_classes):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(100,2), \n",
    "              activation=\"identity\", \n",
    "              solver='sgd', \n",
    "              alpha=0.0001, \n",
    "              batch_size='auto', \n",
    "              learning_rate=\"constant\", \n",
    "              learning_rate_init=0.001, \n",
    "              power_t=0.5, \n",
    "              max_iter=200, \n",
    "              shuffle=True, \n",
    "              random_state=None, \n",
    "              tol=0.0001, \n",
    "              verbose=False, \n",
    "              warm_start=False, \n",
    "              momentum=0.9, \n",
    "              nesterovs_momentum=True, \n",
    "              early_stopping=False, \n",
    "              validation_fraction=0.1, \n",
    "              beta_1=0.9, \n",
    "              beta_2=0.999, \n",
    "              epsilon=1e-08)\n",
    "    mlp.fit(scaled_im_features, np.array(image_classes))\n",
    "    return(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating all the descriptors and keypoints...\n",
      "450/450\n",
      "Done!\n",
      "450/450\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "valimgs,valimage_paths,valimage_classes=opimage(val_image_paths,val_image_classes)\n",
    "lbpvalfeature,lbpvalimage_paths,vallbp_image_classes=lbp1(valimgs,valimage_paths,valimage_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating all the descriptors and keypoints...\n",
      "63325/63325\n",
      "Done!\n",
      "63325/63325\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "imgs,image_paths,image_classes=opimage(image_paths,image_classes)\n",
    "lbpfeature,lbpimage_paths,lbpsift_image_classes=lbp1(imgs,image_paths,image_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating all the descriptors and keypoints...\n",
      "450/450\n",
      "Done!\n",
      "450/450\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "testimgs,testimage_paths,testimage_classes=opimage(test_image_paths,test_image_classes)\n",
    "lbptestfeature,lbptestimage_paths,lbptestsift_image_classes=lbp1(testimgs,testimage_paths,testimage_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=250)\n",
    "lbpfeature=pca.fit_transform(lbpfeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=250)\n",
    "lbptestfeature=pca.fit_transform(lbptestfeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=250)\n",
    "lbpvalfeature=pca.fit_transform(lbpvalfeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbpclf=mlpf(lbpfeature,image_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=lbpclf.predict(lbpvalfeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['27', '38', '38', '43', '44', '46', '38', '38', '47', '36', '44',\n",
       "       '26', '32', '38', '32', '0', '3', '2', '3', '40', '40', '40', '32',\n",
       "       '38', '45', '28', '40', '8', '45', '9', '28', '3', '29', '45',\n",
       "       '20', '0', '27', '47', '45', '7', '38', '27', '40', '16', '20',\n",
       "       '3', '0', '45', '3', '36', '3', '23', '3', '13', '3', '44', '38',\n",
       "       '27', '40', '33', '29', '44', '27', '20', '32', '27', '25', '38',\n",
       "       '45', '9', '28', '40', '47', '28', '45', '32', '37', '25', '43',\n",
       "       '40', '23', '27', '0', '40', '40', '31', '45', '26', '43', '45',\n",
       "       '3', '26', '28', '44', '45', '5', '13', '28', '44', '44', '38',\n",
       "       '32', '38', '38', '13', '20', '40', '47', '44', '20', '17', '28',\n",
       "       '32', '7', '0', '0', '44', '38', '20', '36', '16', '32', '34',\n",
       "       '40', '44', '32', '25', '46', '28', '3', '20', '0', '8', '3', '38',\n",
       "       '32', '23', '47', '44', '7', '36', '16', '40', '20', '17', '45',\n",
       "       '47', '37', '47', '0', '44', '38', '43', '25', '20', '26', '44',\n",
       "       '44', '47', '16', '42', '27', '20', '37', '32', '20', '29', '20',\n",
       "       '40', '25', '40', '40', '38', '45', '26', '20', '20', '43', '20',\n",
       "       '28', '20', '25', '46', '38', '26', '32', '38', '34', '37', '44',\n",
       "       '32', '3', '44', '31', '47', '38', '20', '20', '20', '37', '38',\n",
       "       '20', '16', '40', '32', '37', '26', '47', '26', '40', '34', '38',\n",
       "       '27', '47', '13', '36', '40', '26', '32', '40', '21', '25', '16',\n",
       "       '36', '29', '3', '13', '36', '44', '45', '32', '40', '44', '43',\n",
       "       '45', '3', '45', '34', '38', '27', '44', '45', '47', '16', '9',\n",
       "       '28', '27', '28', '28', '3', '40', '40', '27', '38', '16', '25',\n",
       "       '45', '45', '40', '40', '40', '13', '32', '36', '17', '27', '21',\n",
       "       '38', '45', '44', '40', '20', '26', '0', '25', '47', '17', '3',\n",
       "       '44', '45', '47', '36', '13', '45', '9', '3', '38', '47', '25',\n",
       "       '34', '37', '40', '44', '32', '44', '26', '38', '36', '20', '38',\n",
       "       '7', '20', '44', '16', '38', '39', '25', '32', '20', '44', '28',\n",
       "       '16', '38', '26', '40', '44', '34', '25', '3', '32', '20', '37',\n",
       "       '36', '27', '38', '25', '36', '47', '32', '28', '25', '44', '32',\n",
       "       '20', '37', '20', '38', '34', '20', '20', '34', '42', '17', '20',\n",
       "       '38', '0', '38', '27', '26', '37', '9', '36', '20', '38', '40',\n",
       "       '20', '32', '16', '3', '38', '38', '38', '20', '7', '2', '28', '8',\n",
       "       '40', '43', '20', '40', '20', '40', '40', '45', '40', '20', '36',\n",
       "       '37', '0', '43', '38', '32', '38', '20', '42', '20', '45', '2',\n",
       "       '43', '38', '44', '47', '16', '28', '44', '20', '38', '20', '38',\n",
       "       '38', '38', '45', '20', '38', '28', '3', '45', '2', '44', '40',\n",
       "       '3', '27', '28', '35', '37', '38', '40', '34', '16', '39', '40',\n",
       "       '27', '36', '40', '37', '32', '20', '47', '40', '44', '9', '25',\n",
       "       '16', '45', '40', '38', '44', '45', '3', '45', '37', '27', '20',\n",
       "       '36', '20', '38', '10', '23', '37'], dtype='<U2')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028888888888888888"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(val_image_classes,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q=lbpclf.predict(lbptestfeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05333333333333334"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_image_classes,Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
